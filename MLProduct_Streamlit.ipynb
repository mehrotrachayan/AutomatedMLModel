{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[1,2,3,4,np.nan,5,6,\"Hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=pd.Series(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        2\n",
       "2        3\n",
       "3        4\n",
       "4      NaN\n",
       "5        5\n",
       "6        6\n",
       "7    Hello\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=pd.to_numeric(l,errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data\n",
       "0   1.0\n",
       "1   2.0\n",
       "2   3.0\n",
       "3   4.0\n",
       "4   NaN\n",
       "5   5.0\n",
       "6   6.0\n",
       "7   NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.rename(columns={0:'Data'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.fillna(a.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  2.0\n",
       "2  3.0\n",
       "3  4.0\n",
       "4  3.5\n",
       "5  5.0\n",
       "6  6.0\n",
       "7  3.5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('E:\\Data Sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Outlier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "import re\n",
    "temp='\\\\temp.csv'\n",
    "path=os.getcwd()\n",
    "path=path+temp\n",
    "temp1='\\\\temp1.csv'\n",
    "path1=os.getcwd()\n",
    "path1=path1+temp\n",
    "temp2='\\\\temp2.csv'\n",
    "path2=os.getcwd()\n",
    "path2=path2+temp\n",
    "\n",
    "def upload_csv(zxc):\n",
    "    if zxc:\n",
    "        df=pd.read_csv(zxc)\n",
    "        st.dataframe(df)\n",
    "        return df\n",
    "    \n",
    "\n",
    "def upload_xlsx(zxc):\n",
    "    if zxc:\n",
    "        df=pd.read_excel(zxc)\n",
    "        st.dataframe(df)\n",
    "        return df\n",
    "\n",
    "def mvt_mean(df):\n",
    "    if len(df.select_dtypes(include='object').columns)!=0:\n",
    "        new_df=df.fillna(df.mean())\n",
    "        new_df=new_df.fillna(df.select_dtypes(include='object').mode().iloc[0])\n",
    "        st.dataframe(new_df)\n",
    "        new_df.to_csv(path,index=False)\n",
    "        return new_df\n",
    "    else:\n",
    "        new_df=df.fillna(df.mean())\n",
    "        st.dataframe(new_df)\n",
    "        new_df.to_csv(path,index=False)\n",
    "        return new_df\n",
    "\n",
    "def mvt_median(df):\n",
    "    if len(df.select_dtypes(include='object').columns)!=0:\n",
    "        new_df=df.fillna(df.median())\n",
    "        new_df=new_df.fillna(df.select_dtypes(include='object').mode().iloc[0])\n",
    "        st.dataframe(new_df)\n",
    "        new_df.to_csv(path,index=False)\n",
    "        return new_df\n",
    "    else:\n",
    "        new_df=df.fillna(df.median())\n",
    "        st.dataframe(new_df)\n",
    "        new_df.to_csv(path,index=False)\n",
    "        return new_df\n",
    "\n",
    "def mvt_mode(df):\n",
    "    if len(df.select_dtypes(include='number').columns)==0:\n",
    "        new_df=df.fillna(df.select_dtypes(include='object').mode().iloc[0])\n",
    "        st.dataframe(new_df)\n",
    "        new_df.to_csv(path,index=False)\n",
    "        return new_df\n",
    "    else:\n",
    "        st.write('You cannot impute using Mode as the dataset contains only numerical variables')\n",
    "\n",
    "def export_data():\n",
    "    with open('temp.csv','rb') as f:\n",
    "        #contents=csv.reader(f)\n",
    "        df=pd.read_csv(path)\n",
    "        st.sidebar.download_button(label='Download CSV',data=f,mime='text/csv',file_name='Download.csv')\n",
    "        return\n",
    "    \n",
    "def export_ml_data():\n",
    "    with open('temp2.csv','rb') as f:\n",
    "        #contents=csv.reader(f)\n",
    "        df=pd.read_csv(path2)\n",
    "        st.sidebar.download_button(label='Download CSV',data=f,mime='text/csv',file_name='Download.csv')\n",
    "        return\n",
    "def input_split(x):\n",
    "    l=[]\n",
    "    for i in re.split(\"[^0-9.]\", x):\n",
    "        if i != \"\":\n",
    "            l.append(float(i))\n",
    "    return l\n",
    "def Logistic_Regression():\n",
    "    parameters={'penalty':[],'solver':[]}\n",
    "    with st.form(key='my-form'):\n",
    "        penalty=st.selectbox('Penalty',('l1','l2'))\n",
    "        if penalty:\n",
    "            parameters['penalty'].append(penalty)\n",
    "        solver=st.selectbox('Select LIBLINEAR for L1 or LBFS for L2',('liblinear','lbfgs'))\n",
    "        if solver:\n",
    "            parameters['solver'].append(solver)\n",
    "        submit_button = st.form_submit_button(label='Submit') \n",
    "    df=pd.read_csv(path)\n",
    "    cat_col=df.select_dtypes(include='object').columns\n",
    "    for i in cat_col:\n",
    "        df[i] = df[i].astype('category').cat.codes\n",
    "    st.dataframe(df)\n",
    "    x = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:,-1].values  \n",
    "    from sklearn.preprocessing import StandardScaler \n",
    "    std=StandardScaler()\n",
    "    x=std.fit_transform(x)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1234)\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    logmodel = LogisticRegression(max_iter=500)\n",
    "    logmodel.fit(x_train,y_train)\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    #lambdaval = [0.75,0.78,0.79,0.80,0.81,0.82,0.83,0.84]\n",
    "    #lambdaval=[]\n",
    "    if st.checkbox('Hyperparameters'):\n",
    "        numbers = st.text_input(\"Please enter hyperparameters float types numbers separated by comma\")\n",
    "        if numbers:\n",
    "            lambdaval=[float(i) for i in re.split('[^0-9.]', numbers) if i != \"\"]\n",
    "            st.write(list(lambdaval))\n",
    "            st.write(len(lambdaval))\n",
    "            cv_scores=[]\n",
    "            for i,v in enumerate(lambdaval):\n",
    "                logmodel = LogisticRegression(C=lambdaval[i])\n",
    "                scores = cross_val_score(logmodel,x_train,y_train,cv=5, scoring='accuracy')\n",
    "                cv_scores.append(scores.mean())\n",
    "            MSE = [1-x for x in cv_scores]\n",
    "            optimal_l = lambdaval[MSE.index(min(MSE))]\n",
    "            st.write('The Optimal Value of LAMBDA(Hyperparameter) is',optimal_l)\n",
    "            t1=pd.DataFrame(lambdaval,columns=['lambdaval'])\n",
    "            t2=pd.DataFrame(MSE,columns=['MSE'])\n",
    "            chart_data=pd.concat([t1,t2],axis=1)\n",
    "            fig=px.line(data_frame=chart_data,x='lambdaval',y='MSE')\n",
    "            st.write(fig)\n",
    "            st.write('Tuning the model with Optimal Hyperparameters')\n",
    "            a=parameters['penalty'][0]\n",
    "            b=parameters['solver'][0]\n",
    "            log_optimal = LogisticRegression(penalty=a,C=optimal_l,tol=0.001,max_iter=10000,solver=b)            \n",
    "            log_optimal.fit(x_train,y_train)\n",
    "            y_pred_logit = log_optimal.predict(x_test)\n",
    "            st.dataframe(y_pred_logit)\n",
    "            #target_names = ['Positve(1)', 'Negative(0)']\n",
    "            clsf_report = pd.DataFrame(classification_report(y_true=y_test,y_pred=y_pred_logit,output_dict=True)).transpose()\n",
    "            cls=pd.DataFrame(clsf_report)\n",
    "            st.dataframe(cls)\n",
    "            #Pkl_Filename=\"Model.pkl\"\n",
    "            #with open(Pkl_Filename,'wb') as file:\n",
    "                #pickle.dump(log_optimal,file)\n",
    "            return\n",
    "def get_parameters():\n",
    "    parameters={'C':[],'gamma':[],'degree':[],'kernel':[]}\n",
    "    with st.form(key='my-form'):\n",
    "        numbers=st.text_input('Enter the hyperparameters for C in float format seprated by comma')\n",
    "        if numbers:\n",
    "            l1=[float(i) for i in re.split('[^0-9.]', numbers) if i != \"\"]\n",
    "            for i,v in enumerate(l1):\n",
    "                parameters['C'].append(l1[i])\n",
    "        op=st.text_input('Enter the hyperparameters for Gamma in float format seprated by comma')\n",
    "        if op:\n",
    "            l2=[float(i) for i in re.split('[^0-9.]', op) if i != \"\"]\n",
    "            for i,v in enumerate(l2):\n",
    "                parameters['gamma'].append(l2[i])\n",
    "        l3 = st.multiselect('Degree of Polynomial',(2,3,4,5))\n",
    "        if l3:\n",
    "            for i,v in enumerate(l3):\n",
    "                parameters['degree'].append(l3[i])\n",
    "        l4 = st.multiselect('Kernel',('rbf','poly','sigmoid'))\n",
    "        if l4:\n",
    "            for i,v in enumerate(l4):\n",
    "                parameters['kernel'].append(l4[i])\n",
    "        #st.form_submit_button()\n",
    "        submit_button = st.form_submit_button(label='Submit')\n",
    "    return parameters\n",
    "        \n",
    "    \n",
    "    \n",
    "def Support_Vector_Machine():\n",
    "    parameters={'C':[],'gamma':[],'degree':[],'kernel':[]}\n",
    "    with st.form(key='my-form'):\n",
    "        #parameters={'C':[],'gamma':[],'degree':[],'kernel':[]}\n",
    "        numbers=st.text_input('Enter the hyperparameters for C in float format seprated by comma')\n",
    "        if numbers:\n",
    "            l1=[float(i) for i in re.split('[^0-9.]', numbers) if i != \"\"]\n",
    "            for i,v in enumerate(l1):\n",
    "                parameters['C'].append(l1[i])\n",
    "        op=st.text_input('Enter the hyperparameters for Gamma in float format seprated by comma')\n",
    "        if op:\n",
    "            l2=[float(i) for i in re.split('[^0-9.]', op) if i != \"\"]\n",
    "            for i,v in enumerate(l2):\n",
    "                parameters['gamma'].append(l2[i])\n",
    "        l3 = st.multiselect('Degree of Polynomial',(2,3,4,5))\n",
    "        if l3:\n",
    "            for i,v in enumerate(l3):\n",
    "                parameters['degree'].append(l3[i])\n",
    "        l4 = st.multiselect('Kernel',('rbf','poly','sigmoid'))\n",
    "        if l4:\n",
    "            for i,v in enumerate(l4):\n",
    "                parameters['kernel'].append(l4[i])\n",
    "        #st.form_submit_button()\n",
    "        submit_button = st.form_submit_button(label='Submit')\n",
    "    if st.button('Run'):\n",
    "        #s=0\n",
    "        #for i,v in parameters.items():\n",
    "        #s+=len(v)\n",
    "        #if s>=3:\n",
    "        df=pd.read_csv(path)\n",
    "        cat_col=df.select_dtypes(include='object').columns\n",
    "        for i in cat_col:\n",
    "            df[i] = df[i].astype('category').cat.codes\n",
    "        st.dataframe(df)\n",
    "        x = df.iloc[:, :-1].values\n",
    "        y = df.iloc[:,-1].values  \n",
    "        std=StandardScaler()\n",
    "        x=std.fit_transform(x)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1234)\n",
    "        model_svm=SVC(probability=True)\n",
    "        model_svm.fit(x_train,y_train)\n",
    "        #p=get_parameters()\n",
    "        grid_search=GridSearchCV(estimator=model_svm,param_grid=parameters,scoring='accuracy',cv=10,n_jobs=-1)\n",
    "        grid_search.fit(x_train,y_train)\n",
    "        st.write('Hyperparameters tuned')\n",
    "        st.write(grid_search.best_params_)\n",
    "        p=grid_search.best_params_\n",
    "        model_svm_optimal=SVC(C=p['C'],kernel=p['kernel'],gamma=p['gamma'],degree=p['degree'])\n",
    "        model_svm_optimal.fit(x_train,y_train)\n",
    "        y_pred_test=model_svm_optimal.predict(x_test)\n",
    "        y_pred_test=pd.DataFrame(y_pred_test,columns=['Y_Pred'])\n",
    "        st.dataframe(y_pred_test)\n",
    "        clsf_report = pd.DataFrame(classification_report(y_true=y_test,y_pred=y_pred_test,output_dict=True)).transpose()\n",
    "        #d=classification_report(y_true=y_test,y_pred=y_pred_test,output_dict=True)\n",
    "        cls=pd.DataFrame(clsf_report)\n",
    "        st.dataframe(cls)\n",
    "        return\n",
    "    #else:\n",
    "    #st.write('Cannot run until the hyperparameters are entered')\n",
    "def k_means():\n",
    "    df=pd.read_csv(path)\n",
    "    st.write(df)\n",
    "    num_columns=st.multiselect(\"Select two numerical features\",((df.select_dtypes(include='number').columns)))\n",
    "    inp=st.number_input('Enter the number of clusters')\n",
    "    l=[]\n",
    "    col=[]\n",
    "    for i in range(int(inp)):\n",
    "        l.append(i)\n",
    "    if st.checkbox('Run KMeans Algo'):\n",
    "        x=df.loc[:,num_columns].values\n",
    "        st.write(x)\n",
    "        std=StandardScaler()\n",
    "        x=std.fit_transform(x)\n",
    "        wcss=[]\n",
    "        for i in range(1,11):\n",
    "            kmeans=KMeans(n_clusters=i,init='k-means++')\n",
    "            kmeans.fit(x)\n",
    "            wcss.append(kmeans.inertia_)\n",
    "        fig,ax=plt.subplots()    \n",
    "        ax=plt.plot(range(1,11),wcss)\n",
    "        plt.title('The Elbow Method')\n",
    "        plt.xlabel('no of clusters')\n",
    "        plt.ylabel('wcss')\n",
    "        st.pyplot(fig)\n",
    "        optimal_clusters=st.number_input('From the figure enter the optimal number of cluster')\n",
    "        if st.checkbox('Tune'):\n",
    "            kmeans=KMeans(n_clusters=int(optimal_clusters),init='k-means++')\n",
    "            y_kmeans=kmeans.fit_predict(x)\n",
    "            output=pd.concat([df,pd.DataFrame(y_kmeans)],axis=1)\n",
    "            output.rename(columns={0:'Clusters'},inplace=True)\n",
    "            fig,ax=plt.subplots()\n",
    "            for i in range(int(inp)):\n",
    "                ax.scatter(x[y_kmeans==l[i],0],x[y_kmeans==l[i],1],s=50, label='Cluster %i'%i)\n",
    "                ax.legend()\n",
    "            ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 20, c = 'black', label = 'Centroids')\n",
    "            ax.legend()\n",
    "            #plt.title('Clusters of customers')\n",
    "            plt.xlabel(num_columns[0])\n",
    "            plt.ylabel(num_columns[1])\n",
    "            st.pyplot(fig)\n",
    "            with st.form('my-form1'):\n",
    "                l={}\n",
    "                k=[i for i in range(int(optimal_clusters))]\n",
    "                for i in k:\n",
    "                    l[int(i)]=0\n",
    "                st.write(l)    \n",
    "                for i in range(int(optimal_clusters)):\n",
    "                    x=st.text_input('Enter the name for Cluster %i wrt to the scatter plot'%i)\n",
    "                    l[i]=x\n",
    "                d = {int(k):v for k,v in l.items()}\n",
    "                submit_button = st.form_submit_button(label='Submit')\n",
    "            if st.button('Map the label names'):\n",
    "                st.write(d)\n",
    "                output.Clusters=output.Clusters.map(d)    \n",
    "                st.dataframe(output)\n",
    "                output.to_csv(path,index=False)\n",
    "                export_data()\n",
    "            \n",
    "            #plt.xlabel('Annual Income (k$)')\n",
    "            #plt.ylabel('Spending Score (1-100)')\n",
    "            #st.pyplot(fig)\n",
    "def DBScanClustering():\n",
    "    df=pd.read_csv(path)\n",
    "    st.write(df)\n",
    "    num_columns=st.multiselect(\"Select two numerical features\",((df.select_dtypes(include='number').columns)))\n",
    "    if st.button('Run DBScan Algo'):\n",
    "        x=df.loc[:,num_columns].values\n",
    "        st.write(x)\n",
    "        std=StandardScaler()\n",
    "        x=std.fit_transform(x)\n",
    "        dbscan=DBSCAN(eps=0.5,min_samples=4,metric='euclidean')\n",
    "        y_pred=dbscan.fit(x)\n",
    "        output=pd.concat([df,pd.DataFrame(y_pred.labels_)],axis=1)\n",
    "        output.rename(columns={0:'Clusters'},inplace=True)\n",
    "        fig=sns.lmplot(data=output, x=num_columns[0],y=num_columns[1],hue='Clusters',fit_reg=False)\n",
    "        st.pyplot(fig)\n",
    "        \n",
    "st.title('Front end DPre/DV/ML Project ')\n",
    "option = st.sidebar.selectbox('DSA Application',('Data-PreProcessing', 'Data-Visualization', 'Machine-Learning'))\n",
    "st.sidebar.write('You selected:', option)\n",
    "if option=='Data-PreProcessing':\n",
    "    format_options=['csv','xlsx']\n",
    "    a=st.sidebar.radio('Choose the file type',format_options)\n",
    "    if a=='csv':\n",
    "        b=st.sidebar.file_uploader(\"Choose a file\",type='csv')\n",
    "        if b :\n",
    "            if st.sidebar.checkbox('Upload File'):\n",
    "                df=upload_csv(b)\n",
    "                opt=st.sidebar.radio('Impute Missing Value using',('Mean','Median','Mode'))\n",
    "                st.sidebar.write('You selected',opt)\n",
    "                if opt=='Mean':\n",
    "                    mvt_mean(df)\n",
    "                    export_data()\n",
    "                elif opt=='Median':\n",
    "                    mvt_median(df)\n",
    "                    export_data()\n",
    "                elif opt=='Mode':\n",
    "                    mvt_mode(df)\n",
    "                    export_data()\n",
    "    elif a=='xlsx':\n",
    "        b=st.sidebar.file_uploader(\"Choose a file\",type='xlsx')\n",
    "        if b :\n",
    "            if st.sidebar.checkbox('Upload File'):\n",
    "                df=upload_xlsx(b)\n",
    "                opt=st.sidebar.radio('Impute Missing Value using',('Mean','Median','Mode'))\n",
    "                st.sidebar.write('You selected',opt)\n",
    "                if opt=='Mean':\n",
    "                    mvt_mean(df)\n",
    "                    export_data()\n",
    "                elif opt=='Median':\n",
    "                    mvt_median(df)\n",
    "                    export_data()\n",
    "                elif opt=='Mode':\n",
    "                    mvt_mode(df)\n",
    "                    export_data()\n",
    "elif option=='Data-Visualization':\n",
    "    format_options=['csv','xlsx']\n",
    "    a=st.sidebar.radio('Choose the file type',format_options)\n",
    "    if a=='csv':\n",
    "        b=st.sidebar.file_uploader(\"Choose a file\",type='csv')\n",
    "        if b :\n",
    "            if st.sidebar.checkbox('Upload File'):\n",
    "                df=upload_csv(b)\n",
    "                cat_columns=st.multiselect(\"Select categorical features\",((df.select_dtypes(include='object').columns)))\n",
    "                num_columns=st.multiselect(\"Select numerical features\",((df.select_dtypes(include='number').columns)))\n",
    "                if (len(cat_columns)==1 and len(num_columns)==1):\n",
    "                    options=st.selectbox(\"Select Chart Type\",['Bar-Chart','PieChart','KDEPlot'])\n",
    "                    if options=='Bar-Chart':\n",
    "                        st.bar_chart(df.groupby(cat_columns)[num_columns].mean())\n",
    "                        #st.write(df[cat_columns].columns)\n",
    "                    elif options=='PieChart':\n",
    "                        x=df.groupby(cat_columns)[num_columns].sum()\n",
    "                        d=pd.DataFrame(x).reset_index()\n",
    "                        d=dict(d.values)\n",
    "                        fig, ax1 = plt.subplots()\n",
    "                        ax1.pie(list(d.values()),labels=list(d.keys()),autopct=\"%.1f%%\")\n",
    "                        st.pyplot(fig)\n",
    "                    elif options=='KDEPlot':\n",
    "                        cat=cat_columns[0]\n",
    "                        num=num_columns[0]\n",
    "                        #st.write(cat_columns)\n",
    "                        fig=sns.FacetGrid(df,col=cat).map(sns.kdeplot,num)\n",
    "                        st.pyplot(fig)\n",
    "                elif (len(cat_columns)==1 and len(num_columns)==2):\n",
    "                    options=st.selectbox(\"Select Chart Type\",['Pair-Plot','ScatterPlot'])\n",
    "                    if options=='Pair-Plot':\n",
    "                        #st.write(num_columns[0])\n",
    "                        #st.write(num_columns[1])\n",
    "                        fig=sns.pairplot(df,hue=cat_columns[0], vars=[num_columns[0],num_columns[1]])\n",
    "                        st.pyplot(fig)\n",
    "                    elif options=='ScatterPlot': \n",
    "                        a=sns.scatterplot(data=df,x=num_columns[0],y=num_columns[1],hue=cat_columns[0])\n",
    "                        st.pyplot(a.figure)\n",
    "                elif (len(cat_columns)==0 and len(num_columns)==2):\n",
    "                    options=st.selectbox(\"Select Chart Type\",['Pair-Plot','ScatterPlot'])\n",
    "                    if options=='Pair-Plot':\n",
    "                        fig=sns.pairplot(df,vars=[num_columns[0],num_columns[1]])\n",
    "                        st.pyplot(fig)\n",
    "                    elif options=='ScatterPlot':\n",
    "                        a=sns.scatterplot(data=df,x=num_columns[0],y=num_columns[1])\n",
    "                        st.pyplot(a.figure)\n",
    "elif option=='Machine-Learning':\n",
    "    format_options=['csv','xlsx']\n",
    "    a=st.sidebar.radio('Choose the file type',format_options)\n",
    "    if a=='csv':\n",
    "        b=st.sidebar.file_uploader(\"Choose a file\",type='csv')\n",
    "        if b :\n",
    "            if st.sidebar.checkbox('Upload File'):\n",
    "                df=upload_csv(b)\n",
    "                opt=st.sidebar.radio('Impute Missing Value using',('Mean','Median','Mode'))\n",
    "                st.sidebar.write('You selected',opt)\n",
    "                if opt=='Mean':\n",
    "                    mvt_mean(df)\n",
    "                    \n",
    "                elif opt=='Median':\n",
    "                    mvt_median(df)\n",
    "                    \n",
    "                elif opt=='Mode':\n",
    "                    mvt_mode(df)\n",
    "                    \n",
    "    elif a=='xlsx':\n",
    "        b=st.sidebar.file_uploader(\"Choose a file\",type='xlsx')\n",
    "        if b :\n",
    "            if st.sidebar.checkbox('Upload File'):\n",
    "                df=upload_xlsx(b)\n",
    "                opt=st.sidebar.radio('Impute Missing Value using',('Mean','Median','Mode'))\n",
    "                st.sidebar.write('You selected',opt)\n",
    "                if opt=='Mean':\n",
    "                    mvt_mean(df)\n",
    "                    \n",
    "                elif opt=='Median':\n",
    "                    mvt_median(df)\n",
    "                \n",
    "                elif opt=='Mode':\n",
    "                    mvt_mode(df)\n",
    "\n",
    "    #if st.sidebar.checkbox(\"Build\"):\n",
    "        #ml_options=['Linear Regression','Classification']\n",
    "    st.sidebar.write('Choose a ML Method depending upon the data')\n",
    "    if  st.sidebar.checkbox('Regression'):\n",
    "        df=pd.read_csv(path)\n",
    "        df1=pd.read_csv(path1)\n",
    "        col_name = st.selectbox(\"Please Enter the name of column to predict\",df.select_dtypes(exclude='object').columns)\n",
    "        #y = df.loc[:,col_name].values\n",
    "        #df=df.drop([col_name], axis = 1)\n",
    "        #x = df.loc[:].values\n",
    "        y=df[col_name]\n",
    "        y1=df[col_name]\n",
    "        df=df.drop([col_name], axis = 1)\n",
    "        df1=df1.drop([col_name],axis=1)\n",
    "        x=df\n",
    "        st.dataframe(y)\n",
    "        st.dataframe(x)\n",
    "        from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        labelencoder = LabelEncoder()\n",
    "        cat_columns=list(df.select_dtypes(include='object').columns)\n",
    "        cat_columns1=list(df1.select_dtypes(include='object').columns)\n",
    "        for i in range(len(cat_columns)):\n",
    "            x.loc[:,cat_columns[i]] = labelencoder.fit_transform(x.loc[:,cat_columns[i]])\n",
    "        st.dataframe(x)\n",
    "        for i in range(len(cat_columns1)):\n",
    "            df1.loc[:,cat_columns1[i]] = labelencoder.fit_transform(df1.loc[:,cat_columns1[i]])\n",
    "        x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1)\n",
    "        regressor=LinearRegression()\n",
    "        regressor.fit(x_train,y_train)\n",
    "        st.write(\"Model Build Successfully\")\n",
    "        st.write(\"Please play with the sliders to give input\")\n",
    "        l=[]\n",
    "        for i in df1:\n",
    "            l.append(st.sidebar.slider('{}'.format(i),min(df1[i]),max(df1[i]),min(df1[i])))\n",
    "        #st.sidebar.slider(\"Choose a range\",0,100,60) \n",
    "        if st.button(\"Predict\"):\n",
    "            y_pred=regressor.predict([l])\n",
    "            st.write(\"Your predicted {} is {:.2f}\".format(col_name,float(y_pred)))\n",
    "            y_pred1=regressor.predict(x_test)\n",
    "            #st.dataframe(y_pred1)\n",
    "            y_pred1=pd.DataFrame(y_pred1)\n",
    "            y_pred1=y_pred1.rename(columns={0:'Predicted %s'%col_name})\n",
    "            st.dataframe(y_pred1)\n",
    "            from sklearn.metrics import r2_score\n",
    "            coefficient_of_dermination = r2_score(y_test,y_pred1)\n",
    "            st.write('R Square ',coefficient_of_dermination)\n",
    "    elif st.sidebar.checkbox('Classification'):\n",
    "        algo=['Logistic Regression','Support-Vector-Machine']\n",
    "        ch = st.selectbox(\"Please Select the Classification Algorithm\",algo)\n",
    "        if ch=='Logistic Regression':\n",
    "            Logistic_Regression()\n",
    "        elif ch=='Support-Vector-Machine':\n",
    "            Support_Vector_Machine()\n",
    "    elif st.sidebar.checkbox('Clustering'):\n",
    "        algo=['KMeans','DBScanClustering']\n",
    "        ch = st.selectbox(\"Please Select the Clustering Algorithm\",algo)\n",
    "        if ch=='KMeans':\n",
    "            k_means()\n",
    "        elif ch=='DBScanClustering':\n",
    "            DBScanClustering()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "Pkl_Filename=\"Model.pkl\"\n",
    "with open(Pkl_Filename,'wb') as file:\n",
    "    pickle.dump(log_optimal,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Pkl_Filename,'rb') as file:\n",
    "    logistic_model=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "os.getcwd()\n",
    "os.chdir(r'C:\\Users\\win10\\OneDrive\\Desktop\\Streamlit')\n",
    "# \"/app/{repository name}/ {file.extension}\"\n",
    "#Pkl_Filename = \"/app/pickle_demo_streamlit/Model.pkl\"\n",
    "def upload_csv(zxc):\n",
    "    if zxc:\n",
    "        df=pd.read_csv(zxc)\n",
    "        st.dataframe(df)\n",
    "        return df\n",
    "    \n",
    "Pkl_Filename=\"Model.pkl\"\n",
    "with open(Pkl_Filename, 'rb') as file: \n",
    "    LR_model = pickle.load(file)\n",
    "    \n",
    "\n",
    "st.title('Logistic Regeression Model')\n",
    "st.write('Upload the file containing Xi\\'s')\n",
    "b=st.file_uploader(\"Choose a file\",type='csv')\n",
    "if b:\n",
    "    if st.checkbox('Upload File'):\n",
    "        df=upload_csv(b)\n",
    "        from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "        cat_columns=list(df.select_dtypes(include='object').columns)\n",
    "        labelencoder = LabelEncoder()\n",
    "        for i in range(len(cat_columns)):\n",
    "                df.loc[:,cat_columns[i]] = labelencoder.fit_transform(df.loc[:,cat_columns[i]])\n",
    "        x=df.iloc[:].values\n",
    "        from sklearn.preprocessing import StandardScaler \n",
    "        std=StandardScaler()\n",
    "        x=std.fit_transform(x)\n",
    "        if st.button('Predict'):\n",
    "            y_pred = LR_model.predict(x)\n",
    "            st.dataframe(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\win10\\OneDrive\\Desktop\\Streamlit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "parameters={'C':[],'gamma':[],'degree':[],'kernel':[]}\n",
    "with st.form(key='my-form'):\n",
    "    numbers=st.text_input('Enter the hyperparameters for C in float format seprated by comma')\n",
    "    if numbers:\n",
    "        l1=[float(i) for i in re.split('[^0-9.]', numbers) if i != \"\"]\n",
    "        for i,v in enumerate(l1):\n",
    "            parameters['C'].append(l1[i])\n",
    "    op=st.text_input('Enter the hyperparameters for Gamma in float format seprated by comma')\n",
    "    if op:\n",
    "        l2=[float(i) for i in re.split('[^0-9.]', op) if i != \"\"]\n",
    "        for i,v in enumerate(l2):\n",
    "            parameters['gamma'].append(l2[i])\n",
    "    l3 = st.multiselect('Degree of Polynomial',(2,3,4,5))\n",
    "    if l3:\n",
    "        for i,v in enumerate(l3):\n",
    "            parameters['degree'].append(l3[i])\n",
    "    l4 = st.multiselect('Kernel',('rbf','poly','sigmoid'))\n",
    "    if l4:\n",
    "        for i,v in enumerate(l4):\n",
    "            parameters['kernel'].append(l4[i])\n",
    "    submit_button = st.form_submit_button(label='Submit')\n",
    "    if submit_button:\n",
    "        st.write(f'Hyperparameters entered {parameters}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " parameters={'C':[],'gamma':[],'degree':[],'kernel':[]}\n",
    "    \n",
    "    numbers=st.text_input('Enter the hyperparameters for C in float format seprated by comma')\n",
    "    #if numbers:\n",
    "    l1=[float(i) for i in re.split('[^0-9.]', numbers) if i != \"\"]\n",
    "    for i,v in enumerate(l1):\n",
    "        parameters['C'].append(l1[i])\n",
    "    op=st.text_input('Enter the hyperparameters for Gamma in float format seprated by comma')\n",
    "    if op:\n",
    "        \n",
    "    l3 = st.multiselect('Degree of Polynomial',(2,3,4,5))\n",
    "    \n",
    "    l4 = st.multiselect('Kernel',('rbf','poly','sigmoid'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "st.title('Lets explore session state and call back functions')\n",
    "if 'nor' not in st.session_state:\n",
    "    st.session_state['nor']=5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a={}\n",
    "a['df']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['df']+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['df']+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df': 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_button = st.form_submit_button(label='Submit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBScanClustering():\n",
    "    df=pd.read_csv(path)\n",
    "    st.write(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
